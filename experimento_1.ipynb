{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFG FER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook contiene el código necesario para la creación de un modelo de clasificación de imágenes de rostros humanos en función del estres emocional que presentan. Para ello, se va a utuilzar un dataset de imágenes pero de tipo .npy que contiene las imágenes de los rostros pero con un formato diferente al habitual, ya que las imágenes están en formato de matriz de píxeles. \n",
    "\n",
    "Los pasos a seguir para la creación del modelo son los siguientes:\n",
    "\n",
    "1. Importar las librerías necesarias\n",
    "2. Cargar el dataset\n",
    "3. Preprocesamiento de los datos\n",
    "4. Creación del modelo\n",
    "5. Entrenamiento del modelo\n",
    "6. Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importar las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:58:34.147462: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 18:58:35.053302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fgalan/miniconda3/lib/:/home/fgalan/miniconda3/lib/:/home/fgalan/miniconda3/envs/myenv/lib/\n",
      "2024-07-16 18:58:35.053412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/fgalan/miniconda3/lib/:/home/fgalan/miniconda3/lib/:/home/fgalan/miniconda3/envs/myenv/lib/\n",
      "2024-07-16 18:58:35.053418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se ha mencionado anteriormente, el dataset que se va a utilizar es un archivo .npy que contiene las imágenes de los rostros en formato de matriz de píxeles. Para cargar el dataset, se utiliza la función `np.load()` de la librería NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataset esta dividido en dos partes, una con las imágenes y otra con las etiquetas. Para la recolección de imágenes se ha utilizado un dataset cuyo escenario experimental consiste en pasos que causan o no causan estrés; lectura de escritura en el idioma nativo, entrevista en el idioma nativo, lectura de escritura en idioma no nativo, entrevista en idioma no nativo.\n",
    "\n",
    "Por lo tanto las distintas carpetas que forma el dataset son:\n",
    "\n",
    "- **Native_Language_Script_Reading** (BAJO ESTRES-NEUTRAL)\n",
    "- **Native_Language_Interview** (BAJO ESTRES)\n",
    "- **Non_Native_Language_Script_Reading** (ALTO ESTRES-NEUTRAL)\n",
    "- **Non_Native_Language_Interview** (ALTO ESTRES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para procesar archivos .npy de la manera que se ha descrito y asignar las etiquetas correspondientes (como \"BAJO ESTRES-NEUTRAL\", \"BAJO ESTRES\", \"ALTO ESTRES-NEUTRAL\", \"ALTO ESTRES\") basadas en el nombre de la carpeta en la que se encuentran, se van a seguir los siguientes pasos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Asignar las etiquetas a las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asignar las etiquetas a las imágenes, se va a utilizar una primero una función que recorra las carpetas del dataset y asigne las etiquetas correspondientes a cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignar_etiqueta(nombre_carpeta):\n",
    "    if nombre_carpeta == \"Native_Language_Interview\":\n",
    "        return \"BAJO ESTRES\"\n",
    "    elif nombre_carpeta == \"Native_Language_Script_Reading\":\n",
    "        return \"BAJO ESTRES-NEUTRAL\"\n",
    "    elif nombre_carpeta == \"Non-native_Language_Interview\":\n",
    "        return \"ALTO ESTRES\"\n",
    "    elif nombre_carpeta == \"Non-native_Language_Script_Reading\":\n",
    "        return \"ALTO ESTRES-NEUTRAL\"\n",
    "    else:\n",
    "        return None  # Por si el nombre de la carpeta no coincide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cargar las imágenes y las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el dataset que se va a utilizar, se van a cargar las imágenes de distintas carpetas, segun la persona que aparece en la imagen, y las etiquetas correspondientes a cada imagen. Dentro de cada carpeta de cada persona, se encuentran las carpetas con las clases de estrés correspondientes, y dentro de cada una de estas carpetas se encuentran las imágenes. Lo que se va a realizar es cargar las imágenes y las etiquetas de cada una de las carpetas de las clases de estrés, y se van a guardar todas las corresponientes a cada persona en un array de numpy. Para asi tener un array de numpy con todas las imágenes y otro con todas las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET/05\n",
      "DATASET/28\n",
      "DATASET/20\n",
      "DATASET/29\n",
      "DATASET/22\n",
      "DATASET/30\n",
      "DATASET/10\n",
      "DATASET/14\n",
      "DATASET/21\n",
      "DATASET/02\n",
      "DATASET/25\n",
      "DATASET/11\n",
      "DATASET/15\n",
      "DATASET/16\n",
      "DATASET/09\n",
      "DATASET/33\n",
      "DATASET/17\n",
      "DATASET/24\n",
      "DATASET/32\n",
      "DATASET/18\n",
      "DATASET/27\n",
      "DATASET/03\n",
      "DATASET/23\n",
      "DATASET/19\n",
      "DATASET/13\n",
      "DATASET/01\n",
      "DATASET/07\n",
      "DATASET/08\n",
      "DATASET/31\n",
      "DATASET/04\n",
      "DATASET/12\n",
      "DATASET/06\n",
      "Etiqueta 'ALTO ESTRES-NEUTRAL': 25600 imágenes\n",
      "Etiqueta 'ALTO ESTRES': 25600 imágenes\n",
      "Etiqueta 'BAJO ESTRES': 25600 imágenes\n",
      "Etiqueta 'BAJO ESTRES-NEUTRAL': 25600 imágenes\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta base de tu DATASET\n",
    "ruta = \"DATASET\"\n",
    "\n",
    "# Definir las subcarpetas que corresponden a cada clase\n",
    "classes = [\"Native_Language_Script_Reading\", \"Native_Language_Interview\",\n",
    "           \"Non-native_Language_Script_Reading\", \"Non-native_Language_Interview\"]\n",
    "\n",
    "# Número deseado de imágenes por clase\n",
    "num_images_per_class = 800\n",
    "\n",
    "# Listas para almacenar las imágenes y las etiquetas\n",
    "imagenes = []\n",
    "etiquetas = []\n",
    "\n",
    "# Recorrer cada persona en el dataset\n",
    "for carpeta_persona in os.listdir(ruta):\n",
    "    ruta_persona = os.path.join(ruta, carpeta_persona)\n",
    "    print(ruta_persona)\n",
    "    if os.path.isdir(ruta_persona):  # Asegurar que es un directorio\n",
    "        # Recorrer cada clase\n",
    "        for cls in classes:\n",
    "            ruta_clase = os.path.join(ruta_persona, cls)\n",
    "            if os.path.exists(ruta_clase):\n",
    "                # Lista todas las imágenes (archivos .npy) en la carpeta de la clase\n",
    "                images = [os.path.join(ruta_clase, img) for img in os.listdir(ruta_clase) if img.endswith('.npy')]            \n",
    "                # Seleccionar 1000 imágenes aleatorias sin repetición\n",
    "                if len(images) >= num_images_per_class:\n",
    "                    selected_images = random.sample(images, num_images_per_class)\n",
    "                else:\n",
    "                    selected_images = images  # Si hay menos de 1000, tomar todas\n",
    "                \n",
    "                # Añadir las imágenes seleccionadas y sus etiquetas a las listas\n",
    "                for ruta_imagen in selected_images:\n",
    "                    imagen = np.load(ruta_imagen, allow_pickle=True)\n",
    "                    imagenes.append(imagen)\n",
    "                    etiquetas.append(asignar_etiqueta(cls))\n",
    "                    \n",
    "# Contar etiquetas por clase\n",
    "conteo_etiquetas = {etiqueta: etiquetas.count(etiqueta) for etiqueta in set(etiquetas)}\n",
    "\n",
    "# Número de etiquetas creadas por clase\n",
    "for etiqueta, conteo in conteo_etiquetas.items():\n",
    "    print(f\"Etiqueta '{etiqueta}': {conteo} imágenes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Visualizar las imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de continuar con el preprocesamiento de los datos, se van a visualizar algunas de las imágenes del dataset para comprobar que se han cargado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes cargadas: 102400\n",
      "Número de etiquetas cargadas: 102400\n"
     ]
    }
   ],
   "source": [
    "# Comprobar que se han cargado las imágenes\n",
    "print(\"Número de imágenes cargadas:\", len(imagenes))\n",
    "print(\"Número de etiquetas cargadas:\", len(etiquetas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a visualizar el número de imágenes que hay en cada categoría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imágenes por etiqueta: Counter({'BAJO ESTRES-NEUTRAL': 25600, 'BAJO ESTRES': 25600, 'ALTO ESTRES-NEUTRAL': 25600, 'ALTO ESTRES': 25600})\n"
     ]
    }
   ],
   "source": [
    "# Contar cuántas imágenes hay de cada etiqueta\n",
    "from collections import Counter\n",
    "\n",
    "conteo = Counter(etiquetas)\n",
    "print(\"Número de imágenes por etiqueta:\", conteo)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se han cargado las imágenes y las etiquetas, se van a preprocesar los datos para poder utilizarlos en el modelo de clasificación. Para ello, se van a seguir los siguientes pasos:\n",
    "\n",
    "- Normalizar las imágenes\n",
    "- Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "- Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Normalizar las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102400, 256, 7, 7)\n",
      "(102400, 256, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "# Convertir la lista de imágenes a un array de NumPy para facilitar el procesamiento\n",
    "imagenes = np.array(imagenes, dtype=\"float32\")\n",
    "print(imagenes.shape)\n",
    "\n",
    "# Normalizar las imágenes dividiendo los valores de los píxeles por 255\n",
    "imagenes = imagenes / 255\n",
    "print(imagenes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Dividir los datos en conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos el conjunto de entrenamiento y el conjunto de pruebas para evaluar el rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Convertir las etiquetas a un array de NumPy\n",
    "etiquetas = np.array(etiquetas)\n",
    "# print(etiquetas)\n",
    "\n",
    "# Dividir los datos en datos de entrenamiento y datos de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(imagenes, etiquetas, test_size=0.2, random_state=42, stratify=etiquetas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.3 Codificar las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "[[0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Para modelos de clasificación, especialmente en Keras/TensorFlow, las etiquetas deben estar codificadas de manera que cada etiqueta sea un vector binario. Esto se conoce como codificación one-hot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Codificar las etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Apliar la codificación one-hot\n",
    "y_train_categorical = to_categorical(y_train_encoded)\n",
    "y_test_categorical = to_categorical(y_test_encoded)\n",
    "\n",
    "# Comprobar las etiquetas codificadas\n",
    "print(y_train_categorical)\n",
    "print(y_test_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se han preprocesado los datos, se va a crear el modelo de clasificación de imágenes de rostros humanos en función del estrés emocional que presentan. Para ello, se va a utilizar una red neuronal densa capas totalmente conectadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Definición de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se van a explicar los modelos que se van a utilizar para la clasificación de las imágenes. Todos los modelos que se muestran en este apartado son redes neuronales densas.\n",
    "Todos estos modelos se han elegido debido a que a lo largo del tiempo se han utilizado para diferentes objetivos de clasificación y han obtenido buenos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Modelo Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:59:33.996811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:33.997102: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.015167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.015418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.015641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.015860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.016881: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-16 18:59:34.338937: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.339231: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.339460: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.339676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.339891: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:34.340106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.013376: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.013656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.022072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.022337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.022586: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.022930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22263 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "2024-07-16 18:59:35.023572: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-16 18:59:35.023760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 6089 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(256, 7, 7)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')  # Asume 4 clases como en tu ejemplo\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilar y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:59:35.371737: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3699376128 exceeds 10% of free system memory.\n",
      "2024-07-16 18:59:37.508070: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3699376128 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 18:59:40.222222: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-07-16 18:59:40.232978: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f0692d5d250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-16 18:59:40.232995: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-07-16 18:59:40.233000: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (1): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-07-16 18:59:40.245253: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-16 18:59:40.413802: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 7s 2ms/step - loss: 0.1899 - accuracy: 0.9331 - val_loss: 0.0650 - val_accuracy: 0.9790\n",
      "Epoch 2/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0611 - accuracy: 0.9802 - val_loss: 0.0374 - val_accuracy: 0.9873\n",
      "Epoch 3/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0435 - accuracy: 0.9854 - val_loss: 0.0273 - val_accuracy: 0.9913\n",
      "Epoch 4/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0338 - accuracy: 0.9886 - val_loss: 0.0250 - val_accuracy: 0.9910\n",
      "Epoch 5/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0254 - val_accuracy: 0.9911\n",
      "Epoch 6/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0196 - val_accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0211 - accuracy: 0.9930 - val_loss: 0.0213 - val_accuracy: 0.9924\n",
      "Epoch 8/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0189 - accuracy: 0.9934 - val_loss: 0.0156 - val_accuracy: 0.9951\n",
      "Epoch 9/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.0237 - val_accuracy: 0.9924\n",
      "Epoch 10/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0159 - val_accuracy: 0.9941\n"
     ]
    }
   ],
   "source": [
    "# Antes de entrenar el modelo, debes compilarlo, especificando la función de pérdida y el optimizador que utilizarás.\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train_categorical, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 19:00:32.751584: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1027604480 exceeds 10% of free system memory.\n",
      "2024-07-16 19:00:33.415522: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 1027604480 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9935\n",
      "Precisión en el conjunto de prueba: 0.993457019329071\n",
      "Pérdida en el conjunto de prueba: 0.023823585361242294\n"
     ]
    }
   ],
   "source": [
    "# Validación del modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_categorical)\n",
    "print('Precisión en el conjunto de prueba:', test_acc)\n",
    "print('Pérdida en el conjunto de prueba:', test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Modelo LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "# Asumiendo que tus datos son características extraídas (256 características por cada una de las 7x7 \"imágenes\")\n",
    "model_LeNet = Sequential([\n",
    "    Flatten(input_shape=(256, 7, 7)), # Aplanamos las características para hacerlas compatibles con capas densas\n",
    "    Dense(512, activation='relu'), # Aumentamos la dimensión. Ajusta según necesidad.\n",
    "    Dropout(0.5), # Ayuda a prevenir el sobreajuste\n",
    "    Dense(120, activation='relu'), # Capa densa con 120 nodos como en LeNet\n",
    "    Dense(84, activation='relu'), # Capa densa con 84 nodos como en LeNet\n",
    "    Dense(4, activation='softmax') # Capa de salida para 4 clases\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilar y entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 19:00:35.028859: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 3699376128 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2304/2304 [==============================] - 8s 3ms/step - loss: 0.1808 - accuracy: 0.9277 - val_loss: 0.0513 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0887 - accuracy: 0.9682 - val_loss: 0.0377 - val_accuracy: 0.9871\n",
      "Epoch 3/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9731 - val_loss: 0.0396 - val_accuracy: 0.9851\n",
      "Epoch 4/10\n",
      "2304/2304 [==============================] - 6s 2ms/step - loss: 0.0743 - accuracy: 0.9723 - val_loss: 0.0319 - val_accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0614 - accuracy: 0.9780 - val_loss: 0.0274 - val_accuracy: 0.9905\n",
      "Epoch 6/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0675 - accuracy: 0.9747 - val_loss: 0.0283 - val_accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "2304/2304 [==============================] - 5s 2ms/step - loss: 0.0732 - accuracy: 0.9713 - val_loss: 0.0452 - val_accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "2304/2304 [==============================] - 6s 2ms/step - loss: 0.0559 - accuracy: 0.9786 - val_loss: 0.0380 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0567 - accuracy: 0.9778 - val_loss: 0.0305 - val_accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "2304/2304 [==============================] - 6s 3ms/step - loss: 0.0520 - accuracy: 0.9806 - val_loss: 0.0234 - val_accuracy: 0.9923\n"
     ]
    }
   ],
   "source": [
    "# Compilar el modelo\n",
    "model_LeNet.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model_LeNet.fit(X_train, y_train_categorical, batch_size=32, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640/640 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9917\n",
      "Precisión en el conjunto de prueba: 0.991650402545929\n",
      "Pérdida en el conjunto de prueba: 0.03039696253836155\n"
     ]
    }
   ],
   "source": [
    "# Validación del modelo\n",
    "test_loss, test_acc = model_LeNet.evaluate(X_test, y_test_categorical)\n",
    "print('Precisión en el conjunto de prueba:', test_acc)\n",
    "print('Pérdida en el conjunto de prueba:', test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
